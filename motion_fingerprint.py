# -*- coding: utf-8 -*-
"""Motion_Fingerprint.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uymZJLSqUM1rUiqsp3mFwbG54IeL72fq

Hi team!

> This is our main sandbox of code where we can try out stuff quickly and share it fast with the project group. We can move fast and break things here - create a section for your sandbox's bit and build on top of others work. We'll also make a Git later

##Packages Import Section
Import all packages used (visualisation, ML, etc)

This image shows the coordinate system definition we use to process and understand the data
> ![alt text](https://drive.google.com/uc?export=view&id=1ImA9hGKOexy6tPDCeV2lo2T64pMx4KoR)
> ![alt text](https://www.researchgate.net/profile/Anton_Umek/publication/306311098/figure/fig1/AS:396908829921280@1471641847017/Smartphone-with-the-definitions-of-the-local-coordinate-system-and-gyroscope-rotation.png)

Phone is
- pointing down
- screen facing leg

![alt text](https://upload.wikimedia.org/wikipedia/commons/thumb/0/04/Flight_dynamics_with_text_ortho.svg/220px-Flight_dynamics_with_text_ortho.svg.png)


Then
- rotation of leg = roll 
- flexion of leg = pitch
- maybe:(adduction of leg = azimuth)


![alt text](https://i.pinimg.com/564x/df/2e/80/df2e8055c4e4d20fd42d615805ce6321.jpg)
"""

# Installing Packages
!pip install sensormotion # Python package for analyzing sensor-collected human motion data (e.g. physical activity levels, gait dynamics) https://github.com/sho-87/sensormotion

# Importing Modules
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import sensormotion as sm

"""# Data Importing, Cleaning, and Preparation
Importing and cleaning data from the sensor recording apps (Android, iOS, smartwatches), and prepare the data for ML

First let's connect to the Data Drive:
"""

from google.colab import drive
drive.mount('/content/drive')

# RAW Data Input Path
path = '/content/drive/My Drive/Motion_Fingerprint/Data/' + 'phone_datasets/'                 # path to all subjects datasets

# Processed Data Output Path
processed_path = '/content/drive/My Drive/Motion_Fingerprint/Data/phone_datasets_processed/'  # path where to export processed data

"""## **Import and Clean Android Data**
**Manually switch between subjects**

From the iOS or Andoid app format, for each subject we can run the following functions to import which will create a dataframe from all separate data CSVs of all that subject's data.
"""

# Get a list of the subjects
import os
subjects_list = set(os.listdir(path + 'Android/')) - set('readme.txt')
subjects_list

set(os.listdir(path + 'Android/Sergiu_Iliev/'))

dataset_framerate = 100           # frequency of data in Hz
subject_name = 'Sergiu_Iliev/'
folder_names = ['2020-11-10_11-15-06']

# subject_name = 'Alan_Zhu/'
# folder_names = ['2020-10-19_17-23-40', '2020-10-25_18-27-03', '2020-10-25_18-40-54']

"""### Combine all separate sensor channel CSVs into a single merged one for each data session and subject"""

file_names = ['Accelerometer.csv', 'Compass.csv', 'Gravity.csv', 'Gyroscope.csv']

df_merged = pd.DataFrame()                                         # initialize a DataFrame to store all data for this subject

for folder_name in folder_names:
  df = pd.read_csv(str(path + 'Android/' + subject_name + folder_name + '/' + file_names[0]), error_bad_lines=False)
  for i in range(len(file_names)-1):
    df2 = pd.read_csv(str(path + 'Android/' + subject_name + folder_name + '/' + file_names[i+1]), error_bad_lines=False)
    df = df.join(df2.iloc[:, 2:], rsuffix = '_' + file_names[i+1][:-4])
  df.columns = ['Timestamp', 'ms', 'xAcc', 'yAcc', 'zAcc', 'xComp', 'yComp', 'zComp',
                'xGrav', 'yGrav', 'zGrav', 'xGyro', 'yGyro', 'zGyro']
  print(df.tail())

  # Keep the relevant sensor streams and rename the columns in the global format
  df = df[['xAcc', 'yAcc', 'zAcc', 'xGyro', 'yGyro', 'zGyro']]      # dropping all other columns  including the time column since we are only interested in frame rate (assuming constant timesteps)
  df.columns = ['ax', 'ay', 'az', 'wx', 'wy', 'wz']                 # keeping only the accelerations and rotations    

  # Save them to the processed folder 
  df.to_csv(str(processed_path + 'Android/' + subject_name + folder_name[:-1] + '.csv'), index = False)

  df_merged = df_merged.append(df, ignore_index=True)

"""### Visually checking the data to confirm no issues"""

# Look at how the data appears for a few typical gait cycles
df.iloc[:].plot(y=['wx', 'wy', 'wz'], title='Rotations') # x='frames'

df.plot(y=['ax', 'ay', 'az'], title='Accelerations (in g\'s)') # x='time'

"""### View, Clean & Save Android Data
Putting the data into the universal format for a subject (1 dataframe per subject) and saving it back to the drive -- i.e. one dataframe with consistent headings for each subject with all their steps (just of clean steps)

### Visualise data slices
"""

# We need to check the axes are correct i.e. medio-lateral is actually medio lateral (see first part of this notebook)

# Define what section of the data we want to see (span of the rows to plot)
span = [0, 2000]

# Plot the Acceleration signals on comparative axes
fig, ax = plt.subplots(nrows=3, ncols=1, figsize=(10,7))

timesteps=np.arange(span[0],span[1]) 

ax[0].set_title('Medio-lateral (ML) - side to side')
ax[0].plot(timesteps, df.ax[span[0]:span[1]], linewidth=0.5, color='k')

ax[1].set_title('Vertical (VT) - up down')
ax[1].plot(timesteps, df.ay[span[0]:span[1]], linewidth=0.5, color='k')

ax[2].set_title('Antero-posterior (AP) - forwards backwards')
ax[2].plot(timesteps, df.az[span[0]:span[1]], linewidth=0.5, color='k')

fig.subplots_adjust(hspace=.5)

fig.suptitle('G Forces', fontsize=16)

# Plot the Rotation signals on comparative axes
fig, ax = plt.subplots(nrows=3, ncols=1, figsize=(10,7))

timesteps=np.arange(span[0],span[1]) 

ax[0].set_title('Medio-lateral (ML) - side to side')
ax[0].plot(timesteps, df.wx[span[0]:span[1]], linewidth=0.5, color='k')

ax[1].set_title('Vertical (VT) - up down')
ax[1].plot(timesteps, df.wy[span[0]:span[1]], linewidth=0.5, color='k')

ax[2].set_title('Antero-posterior (AP) - forwards backwards')
ax[2].plot(timesteps, df.wz[span[0]:span[1]], linewidth=0.5, color='k')

fig.subplots_adjust(hspace=.5)

fig.suptitle('Rotations', fontsize=16)

"""### Clean the data
We'll find the peaks in the vertical acceleration determine where steps start and stop
"""

df_merged.shape[0]

# change the span to drop the part where subject places the phone in the pocket
span=[5*dataset_framerate,   df_merged.shape[0] - 5*dataset_framerate] # starting at second 5 and ending 5 seconds early to skip the first portion when puttin the phone in the pocket 
timesteps=np.arange(span[0],span[1]) 

# Determine peaks in the vertical acceleration and use this to identify steps
peak_times, peak_values = sm.peak.find_peaks(timesteps, df_merged.ay[span[0]:span[1]], peak_type='valley', min_val=0.6, min_dist=100, plot=True)

peak_times # these are the indices marking the transitions between steps

"""### Resample

We also divide the gait curve into two-step samples and interpolate them into the same length of 128. As each subject in this dataset has a much larger amount of data as compared to the that in Dataset #1, we do not make overlap between the samples. Finally, a total number of 49,275 samples are collected, in which 44,339 samples are used for training, and the rest 4,936 for test.

To prepare the data, here we create a dictionary that stores each step's frames. For each step, we take 128 frames by resampling from the original frames.
"""

num_steps = len(peak_times) - 1 
print(num_steps)
step_dict = {}

for i in range(num_steps):
  # find the frames for each step
  df_step = df_merged.loc[peak_times[i]:peak_times[i+1]]

  original_df_step = df_step.copy() ## save original df 

  ## resample the df to approximately 128 frames using datetime
  df_step.index = pd.to_datetime(df_step.index, unit='ms')
  num_frames = peak_times[i+1] - peak_times[i]
  resample_size = int(num_frames * 1000 / 127)
  resample_size_str = str(resample_size) + 'U'
  df_step = df_step.resample(resample_size_str)

  if resample_size >= 1000:
    ## downsample - take mean of multiple values
    df_step = df_step.mean()
  else:
    ## upsample - interpolate to fill NaN
    df_step = df_step.mean().interpolate(method = 'linear')

  ## drop the datetime index, take first 128 rows
  df_step = df_step.reset_index(drop=True)[:128]

  print('step: {}, original size: {}, resampled size: {}'.format(i+1, original_df_step.shape[0], df_step.shape[0]))

  step_dict[i+1] = df_step

"""Now we convert our data to a dataframe with each row being one step."""

step_arr = np.zeros((num_steps, 128 * 6))
for step in step_dict:
  step_arr[step-1] = step_dict[step].to_numpy().reshape(1, -1)
df_final = pd.DataFrame(step_arr)
print(df_final.shape)

df_final.head()

"""### Save the output"""

# Save the subject data to the processed folder 
df_final.to_csv(str(processed_path + subject_name[:-1] + '.csv'), index=False, header=False)

"""## **Import and Clean iOS Data**

Read all data from folder and combine them with Pandas
"""

ios_dataset_framerate = 60 # frequency of data in Hz

import os
subject_name = 'Jack_Chang/'
file_names = [f for f in os.listdir(str(path + 'iOS/' + subject_name)) if f.endswith('.csv')]
df = pd.read_csv(str(path + 'iOS/' + subject_name + file_names[0]), error_bad_lines=False)

print('Dataframe sizes:')
for f in file_names[1:]:
  df_append = pd.read_csv(str(path + 'iOS/' + subject_name + f), error_bad_lines=False)
  df = df.append(df_append, ignore_index=True)
  print(df.shape)
df.tail()

# Keep the relevant sensor streams and rename the columns in the global format
df.columns = ['time', 'ax', 'ay', 'az', 'GyroX', 'GyroY', 'GyroZ', 'Bx', 'By', 'Bz']
df = df[['ax', 'ay', 'az', 'GyroX', 'GyroY', 'GyroZ']]  # dropping all other colums apart from rotation and acceleration including the time column since we are only interested in frame rate (assuming constant timesteps)
df.columns = ['ax', 'ay', 'az', 'wx', 'wy', 'wz']       # renaming to the universal format 
df.tail()
df_merged = df

"""### View, Clean & Save iOS Data
Putting the data into the universal format for a subject (1 dataframe per subject) and saving it back to the drive -- i.e. one dataframe with consistent headings for each subject with all their steps (just of clean steps)
"""

# change the span to drop the part where subject places the phone in the pocket
span=[5*ios_dataset_framerate,   df_merged.shape[0] - 5*ios_dataset_framerate] # starting at second 5 and ending 5 seconds early to skip the first portion when puttin the phone in the pocket 
timesteps=np.arange(span[0],span[1]) 

# Determine peaks in the vertical acceleration and use this to identify steps
peak_times, peak_values = sm.peak.find_peaks(timesteps, df_merged.ay[span[0]:span[1]], peak_type='valley', min_val=0.6, min_dist=100, plot=True)

"""### Clean the data
We'll find the peaks in the vertical acceleration determine where steps start and stop (see Android part)

### Save the output
"""

df_merged.to_csv(str(processed_path + 'iOS/' + subject_name[:-1] + '.csv'), index = False)

"""# ML Analysis - Gait Extraction

## **CNN**
"""

collab_path = '/content/drive/MyDrive/Motion_Fingerprint/Data/phone_datasets_processed/'

file_names = [f for f in os.listdir(collab_path) if f.endswith('.csv')]
df=pd.DataFrame()
for f in file_names:
  temp_df = pd.read_csv(str(collab_path + f), error_bad_lines=False, header=None)
  temp_df['label']=f.split('.')[0]
  df=pd.concat([df, temp_df], ignore_index=True)

df.loc[df['label']=='Jack_chang (1)', 'label']='Jack_chang'

classes_dict=dict(zip(list(df['label'].unique()), range(len(df['label'].unique()))))

from keras.utils import to_categorical
y=to_categorical(df['label'].map(classes_dict))

X=df.loc[:, df.columns != 'label']
X=np.array(X[:])

from sklearn.model_selection import train_test_split
trainX, testX, trainy, testy=train_test_split(X, y, test_size=0.2, random_state=42)

X_train=trainX.reshape(trainX.shape[0], trainX.shape[1], 1)

X_test=testX.reshape(testX.shape[0], testX.shape[1], 1)

batch_size=10
num_classes=3
epochs=15
input_shape=(X_train.shape[1], 1)

import keras
from keras.models import Model
from keras.models import Sequential
from keras.layers import Conv1D, ZeroPadding1D, MaxPooling1D, BatchNormalization, Activation, Dropout, Flatten, Dense

model=Sequential()

model.add(Conv1D(128, kernel_size=3, padding='same', activation='relu', input_shape=input_shape))
model.add(BatchNormalization())

model.add(MaxPooling1D(pool_size=(2)))

model.add(Conv1D(128, kernel_size=3, padding='same', activation='relu'))

model.add(BatchNormalization())
model.add(MaxPooling1D(pool_size=(2)))

model.add(Flatten())

model.add(Dense(64, activation='tanh'))

model.add(Dropout(0.2))

model.add(Dense(32, activation='tanh'))

model.add(Dropout(0.2))

model.add(Dense(16, activation='relu'))

model.add(Dropout(0.2))

model.add(Dense(num_classes, activation='softmax'))

model.summary()

opt = keras.optimizers.Adam(learning_rate=1e-4, decay=1e-6)

model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])

model.fit(X_train, trainy, epochs=epochs, batch_size=batch_size)

model.evaluate(X_test, testy, batch_size=batch_size)